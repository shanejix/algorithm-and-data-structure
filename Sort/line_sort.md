### 时间复杂度为 O(n)的排序算法

| 排序算法 | 时间复杂度 | 是否基于比较 |
| :------: | :--------: | :----------: |
|  桶排序  |    O(n)    |      否      |
| 计数排序 |    O(n)    |      否      |
| 基数排序 |    O(n)    |      否      |

桶排序、计数排序、基数排序三种排序的时间复杂度是线性的，因此也叫作线性排序（Linear sort）

- 主要原因是，这三个算法是**非基于比较**的排序算法，都不涉及元素之间的比较操作
- 要排序的数据要求很苛刻
- 重点掌握三种排序算法的**适用场景**

#### 桶排序（Bucket sort）

##### 思想：

- 将要排序的数据分到几个**有序的桶**里
- 每个桶里的数据再单独进行排序
- 桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了

  ##### 复杂度分析：桶排序的时间复杂度为什么是 O(n) ？

- 如果要排序的数据有 n 个，把它们均匀地划分到 m 个桶内
- 每个桶里就有 k=n/m 个元素
- 每个桶内部使用快速排序，时间复杂度为 `O(k * logk)`
- m 个桶排序的时间复杂度就是 `O(m * k * logk)`，
- 因为 k=n/m，所以整个桶排序的时间复杂度就是 O(n\*log(n/m))
- 当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)

  ##### 桶排序看起来很优秀，但是桶排序对要排序数据的要求是非常苛刻的：

- 首先，要排序的数据需要很容易就能划分成 m 个桶，
- 并且，桶与桶之间有着天然的大小顺序

  - 这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序

- 其次，数据在各个桶之间的分布是比较均匀的
  - 如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了
  - 在极端情况下，如果数据都被划分到一个桶里，那就退化为 `O(nlogn)` 的排序算法了 #####适用场景：
    桶排序比较适合用在**外部排序**中
    外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中
    > 比如说有 10GB 的订单数据，希望按订单金额（假设金额都是正整数）进行排序，但是内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。这个时候该怎么办呢？
    > 借助桶排序的处理思想:
- 先扫描一遍文件，看订单金额所处的数据范围
- 假设扫描之后得到，订单金额最小是 1 元，最大是 10 万元
- 将所有订单根据金额划分到 100 个桶里，
  - 第一个桶我们存储金额在 1 元到 1000 元之内的订单，
  - 第二桶存储金额在 1001 元到 2000 元之内的订单，
  - 以此类推
- 每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名（00，01，02…99）
- 理想的情况下，如果订单金额在 1 到 10 万之间均匀分布，那订单会被均匀划分到 100 个文件中，
  每个小文件中存储大约 100MB 的订单数据，
- 就可以将这 100 个小文件依次放到内存中，用快排来排序
- 等所有文件都排好序之后，我们只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了
  不过，订单按照金额在 1 元到 10 万元之间并不一定是均匀分布的 ，所以 10GB 订单数据是无法均匀地被划分到 100 个文件中的有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。这又该怎么办呢？
  针对这些划分之后还是比较大的文件，可以**继续划分**
- 比如，订单金额在 1 元到 1000 元之间的比较多，就将这个区间继续划分为 10 个小区间，
- 1 元到 100 元，101 元到 200 元，201 元到 300 元…901 元到 1000 元
- 如果划分之后，101 元到 200 元之间的订单还是太多，无法一次性读入内存，那就**继续再划分**，
- **直到所有的文件都能读入内存为止**

#### 计数排序（Counting sort）

##### 思想：

当要排序的 n 个数据，所处的范围最大值是 k，可以把数据划分成 k 个桶

- 数据的范围不大（k 不大）
- 每个桶内的数据值都是相同的（省掉了桶内排序的时间）
- 可以视为**桶排序的特殊情况**(**桶的大小**不一样)
  > 如果有 50 万考生，如何通过成绩快速排序得出名次呢？
- 考试成绩满分为 k，成绩范围为 0~k（k 的范围不大）
- 扫描遍历 50 万考生成绩，划分到 k+1 个桶里
- 桶内的数据都是分数相同的考生，并不需要再进行排序
- 依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了 50 万考生的排序

##### 时间复杂度

只涉及扫描遍历操作，所以时间复杂度是 O(n)

##### “计数”的含义

举个栗子：
a[n]:包含原始数据的数组 a，数据的范围是 0~k(k<<n);
b[k]:遍历原始数据，将 n 个数据划分到 k+1 个桶中（默认 b[]中数据是按照下标递增的）
c[]:计数排序后的数组
思路：

- 顺序求和 b[]数组，`b[i] (i<k-1)`:代表原始数据中小于等于 i 的数据的个数
- 将`i`追加到 c[]中，`b[i]--`（小于等于`i`的数据个数减一）
- 重复上述步骤

##### 适用场景

计数排序只能用在数据范围不大的场景中

- 如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序
  而且，计数排序只能给非负整数排序
- 如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数

#### 基数排序（Radix sort）

##### 问题：给 10 万个手机号码从小到大排序

- 快排，时间复杂度是 `O(nlogn)`（可以更下吗？）
- 桶排序、计数排序，手机号码 11 位，范围太大
  数据的特点：
  如果 a 手机号码的前面某位数字已经比 b 手机号码大了，就不用继续比较了
  思路：借助稳定排序算法
- 先按照最后一位来排序手机号码，
- 然后，再按照倒数第二位重新排序，
- 以此类推...
- 最后按照第一位重新排序
- 经过 11 次排序之后，手机号码就都有序了
  按照每位来排序的排序算法要是稳定的，否则这个实现思路就是不正确的
  根据每一位来排序，我们可以用桶排序或者计数排序,时间复杂度可以做到 O(n)
  如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k\*n)
  手机号码排序的例子，k 最大就是 11，所以基数排序的时间复杂度就近似于
  O(n)
