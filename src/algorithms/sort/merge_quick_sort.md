### 时间复杂度为`O(nlogn)`的排序算法

| 排序算法 | 事件复杂度 |      |
| :------: | :--------: | :--: |
| 归并排序 | `O(nlogn)` |      |
| 快速排序 | `O(nlogn)` |      |

归并排序和快速排序

- **适合大规模的数据**排序

- 更常用

- 都用到了**分治思想**

#### 归并排序（Merge Sort）

##### 思想：分治思想

- 将待排序数据**从中间分成前后两部分**
- 对前后两部分分别排序
- 将排好序的前后两部分合并，整个数据就有序了

分治算法一般都采用递归来实现：

- 分治——一种解决问题的处理思想
- 递归——一种编程技巧

递归代码的编码技巧

- 递推公式
- 终止条件
- 翻译代码

归并排序的递推公式：

```c++
递推公式：
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))

终止条件：
p >= r 不用再继续分解
```

伪码描述：

```c++
//A 是数组，n 表示数组大小
merge_sort(A, n) {
	merge_sort_c(A, 0, n-1)
}
// 递归调用函数
merge_sort_c(A, p, r) {
    // 递归终止条件
    if p >= r then return
    // 取 p 到 r 之间的中间位置 q
    q = (p+r) / 2
    // 分治递归
    merge_sort_c(A, p, q)
    merge_sort_c(A, q+1, r)
    // 将 A[p...q] 和 A[q+1...r] 合并为 A[p...r]
    merge(A[p...r], A[p...q], A[q+1...r])
}
```

##### merge(A[p…r], A[p…q], A[q+1…r]) 的作用是

- 将已经有序的 A[p…q] 和 A[q+1…r] 合并成一个有序的数组，
- 并且放入 A[p…r]

##### merge()函数如何实现呢？

```c++
merge(A[p...r], A[p...q], A[q+1...r]) {
    var i := p，j := q+1，k := 0 // 初始化变量 i, j, k
    var tmp := new array[0...r-p] // 申请一个大小跟 A[p...r] 一样的临时数组
    while i<=q AND j<=r do {
        if A[i] <= A[j] {
            tmp[k++] = A[i++] // i++ 等于 i:=i+1
        } else {
            tmp[k++] = A[j++]
        }
    }
    // 判断哪个子数组中有剩余的数据
    var start := i，end := q
    if j<=r then start := j, end:=r
    // 将剩余的数据拷贝到临时数组 tmp
    while start <= end do {
        tmp[k++] = A[start++]
    }
    // 将 tmp 中的数组拷贝回 A[p...r]
    for i:=0 to r-p do {
        A[p+i] = tmp[i]
    }
}
```

merge()函数如何借助哨兵简化编程？

to do

归并排序性能分析：

##### 归并排序是稳定的排序算法吗？

关键要看 merge()函数（两个有序子数组合并成一个有序数组）

- 如果 A[p…q] 和 A[q+1…r] 之间有值相同的元素，
- 可以先把 A[p…q] 中的元素放入 tmp 数组
- 这样就保证了值相同的元素，在合并前后的先后顺序不变
- 所以，归并排序可以是一个稳定的排序算法

##### 归并排序的时间复杂度是多少？

归并排序涉及递归

如何分析递归代码的时间复杂度？

- 递归的适用场景是：
  - 一个问题 a 可以分解为多个子问题 b、c，
  - 那么,求解问题 a 就可以分解为求解问题 b、c
  - 问题 b、c 解决之后，再把 b、c 的结果合并成 a 的结果
- 定义:
  - 求解问题 a 的时间是 T(a)，
  - 求解问题 b、c 的时间分别是 T(b) 和 T( c)
- 递推关系式：
  - `T(a) = T(b) + T(c) + K`
  - 其中 K 等于将两个子问题 b、c 的结果合并成问题 a 的结果所消耗的时间

套用递归代码分析归并排序的时间复杂度：

- 假设对 n 个元素进行归并排序需要的时间是 T(n)，那么，分解成两个子数组排序的时间都是 T(n/2)

- merge() 函数合并两个有序子数组的时间复杂度是 O(n)

- 归并排序的时间复杂度的计算公式是：

  ```c++
  T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C
  T(n) = 2*T(n/2) + n； n>1
  ```

  进一步分解计算过程:

  ```c++
  //迭代

  T(n)=2*T(n/2) +n
      = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
      = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
      = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n
      ......
      = 2^k * T(n/2^k) + k * n
      ......
  ```

  当 T(n/2^k)=T(1) 时，也就是 n/2^k=1，我们得到 k=log n
  将 k 值代入上面的公式，得到 T(n)=Cn+nlog n
  用大 O 标记法来表示，T(n) 就等于 O(nlogn)
  所以归并排序的时间复杂度是 O(nlogn)
  归并排序的执行效率**与要排序的原始数组的有序程度无关**，

- 其时间复杂度是非常稳定的，
- 不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)

##### 归并排序的空间复杂度是多少？

归并排序的缺陷是就地排序；
递归代码的空间复杂度并不能像时间复杂度那样累加

- 尽管每次合并操作都需要申请额外的内存空间，
- 但在合并完成之后，临时开辟的内存空间就被释放掉了
- 在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用
- 临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)

#### 快速排序（Quicksort）

##### 思想：分治思想

- 从排序数组 下标从 p 到 r 之间的一组数据中，选择 p 到 r 之间的任意一个数据作为 pivot（分区点）
- 遍历 p 到 r 之间的数据，
  - 将小于 pivot 的放到左边，
  - 将大于 pivot 的放到右边，
  - 将 pivot 放到中间
- 数组 p 到 r 之间的数据就被分成了三个部分，
  - 前面 p 到 q-1 之间都是小于 pivot 的，
  - 中间是 pivot，
  - 后面的 q+1 到 r 之间是大于 pivot 的
- 根据分治、递归的处理思想，
  - 用递归排序 - 下标从 p 到 q-1 之间的数据 - 和下标从 q+1 到 r 之间的数据， - 直到区间缩小为 1，说明所有的数据都有序了
    快排递推公式：

```c++
递推公式：
quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)
终止条件：
p >= r
```

伪代描述：

```c++
//A 是数组，n 表示数组的大小
quick_sort(A, n) {
	quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r为下标
quick_sort_c(A, p, r) {
    if p >= r then return

    q = partition(A, p, r) // 获取分区点

    quick_sort_c(A, p, q-1)
    quick_sort_c(A, q+1, r)
}
```

注意区别：归并排序中的 merge() 合并函数

##### partition() 分区函数作用是

- 随机选择一个元素作为 pivot（一般情况下，可以选择 p 到 r 区间的最后一个元素）
- 然后对 A[p…r] 分区，函数返回 pivot 的下标

##### partition() 分区函数如何实现

- 不考虑空间消耗的话，

  - 可以申请两个临时数组 X 和 Y
  - 遍历 A[p…r]，
    - 将小于 pivot 的元素都拷贝到临时数组 X，
    - 将大于 pivot 的元素都拷贝到临时数组 Y，
    - 最后再将数组 X 和数组 Y 中数据顺序拷贝到 A[p…r]
  - 这种思路，
    - partition() 函数就需要很多额外的内存空间
    - 所以快排就不是原地排序算法了

- 在 A[p…r] 的原地完成分区操作

  ```c++
  //伪码描述
  partition(A, p, r) {
      pivot := A[r]
      i := p
      for j := p to r-1 do {
          if A[j] < pivot {
              swap A[i] with A[j]
              i := i+1
          }
  	}
  	swap A[i] with A[r]
  	return i
  }
  ```

  这里的处理有点类似选择排序：

  - 通过游标 i 把 A[p…r-1] 分成两部分
  - A[p…i-1] 的元素都是小于 pivot 的——“已处理区间”，A[i…r-1] 是“未处理区间”
  - 每次都从未处理的区间 A[i…r-1] 中取一个元素 A[j]，与 pivot 对比，
  - 如果小于 pivot，则将其加入到已处理区间的尾部，也就是 A[i]的位置

分区的过程涉及交换操作，快速排序并不是一个稳定的排序算法

##### 归并排序和快速排序的区别

同：

- 都是分治思想，
- 递推公式和递归代码也非常相似

区别：

归并排序

- 着重：**怎么合**
- 归并排序的处理过程是由下到上的，先处理子问题，然后再合并
- 稳定排序
- 时间复杂度为`O(nlogn)`的排序算法
- 非原地排序

快速排序

- 着重：**怎么分**
- 处理过程是由上到下的，先分区，然后再处理子问题
- 不稳定排序
- 原地排序（原地分区函数，解决了归并排序占用太多内存的问题）

快速排序的性能分析：

##### 快速排序的时间复杂度是多少？

快排也是用递归来实现的

对于递归代码的时间复杂度

如果每次分区操作，都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并是相同的。所以，快排的时间复杂度也是 O(nlogn)

```c++
T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。
T(n) = 2*T(n/2) + n； n>1
```

公式成立的前提是每次分区操作，选择的 pivot 都很合适，
两个极端情况下的时间复杂度:

- 分区极其均衡，
  - 正好能将大区间对等地一分为二,
- 分区极其不均衡
  - 快排的时间复杂度就从 `O(nlogn)` 退化成了 O(n^2)
    在大部分情况下的时间复杂度都可以做到 `O(nlogn)`

##### 快速排序的时间复杂度是多少？

就地排序，O(1)

##### 快速排序是稳定排序吗？

分区的过程涉及交换操作，快速排序并不是一个稳定的排序算法

##### O(n) 时间复杂度内求无序数组中的第 K 大元素

思路：

- 选择数组区间 A[0…n-1] 的最后一个元素 A[n-1] 作为 pivot，对数组 A[0…n-1] 原地分区，
- 分成了三部分
  - A[0…p-1]、A[p]、A[p+1…n-1]
- 如果 p+1=K，
  - A[p] 就是要求解的元素；
- 如果 K>p+1,
  - 说明第 K 大元素出现在 A[p+1…n-1] 区间，再按照上面的思路递归地在 A[p+1…n-1] 这个区间内查找
- 如果 K<p+1，
  - 就在 A[0…p-1] 区间递归查找
    时间复杂度：
- 第一次分区查找，需要对大小为 n 的数组执行分区操作，需要遍历 n 个元素
- 第二次分区查找，只需要对大小为 n/2 的数组执行分区操作，需要遍历 n/2 个元素
- 依次类推，分区遍历元素的个数分别为、n/2、n/4、n/8、n/16.……
- 直到区间缩小为 1
- 把每次分区遍历的元素个数加起来，就是：n+n/2+n/4+n/8+…+1
  - 这是一个等比数列求和，最后的和等于 2n-1
  - 所以，上述解决思路的时间复杂度就为 **O(n)**
    另一种思路：
- 每次取数组中的最小值，将其移动到数组的最前面，
- 然后在剩下的数组中继续找最小值，
- 以此类推，执行 K 次，找到的数据不就是第 K 大元素了
  另一种思路的时间复杂度：
- 是 O(K \* n)
  - 当 K 是比较小的常量时，比如 1、2，最好时间复杂度是 O(n)；
  - 当 K 等于 n/2 或者 n 时，这种坏情下的况时间复杂度就是 O(n ) ；
