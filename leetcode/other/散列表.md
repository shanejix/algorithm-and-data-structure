散列表的英文叫“Hash Table”，也叫作“哈希表”或者“Hash 表”

散列表用的是数组支持按照下标随机访问数据的特性（时间复杂度是 O(1) 的特性）（数组的一种扩展）由数组演化而来

#### 散列思想

- 通过**散列函数**把元素的**键值（key）**（或者关键字）映射为下标，然后将数据存储在数组中对应下标的位置

- 当按照键值查询元素时，用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据

- 转化为数组下标的映射方法就叫作**散列函数（或“Hash 函数”“哈希函数”）**

- 而散列函数计算得到的值就叫作**散列值（或“Hash 值”“哈希值**”）

#### 散列函数

散列函数在散列表中起着非常关键的作用

###### 散列函数设计的基本要求

1. 散列函数计算得到的散列值是一个**非负整数**；
2. 如果 key1 = key2，那 hash(key1) == hash(key2)；
3. 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)

但是在真实的情况下，

- 要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的
- 业界著名的MD5、SHA、CRC等哈希算法，也无法完全避免这种散列冲突
- 而且，数组的存储空间有限，也会加大散列冲突的概率

######如何设计散列函数

散列函数设计的好坏，决定了散列表冲突的概率大小，也直接决定了散列表的性能

散列函数的设计设计：

- 不能太复杂
- 散列值尽可能随机并且均匀分布
- 综合考虑各种因素
  - 关键字的长度、特点、分布、
  - 散列表的大小等

数据分析法

- 手机号码
  - 取手机号的后四位作为散列值
  - 手机号码前几位重复的可能性很大

直接寻址法

平方取中法

折叠法

随机数法

#### 散列冲突

##### 解决方案

常用的散列冲突解决方法有两类

######开放寻址法

核心思想:

- 如果出现了散列冲突，就重新探测一个空闲位置，将其插入

如何重新探测新的位置?

- 线性探测（Linear Probing）
  - 当往散列表中插入数据时，
    - 如果某个数据经过散列函数散列之后，存储位置已经被占用了，
    - 就从当前位置开始，依次往后查找，看是否有空闲位置，
    - 如果遍历到尾部都没有找到空闲的位置，
    - 于是再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置
  - 在散列表中查找元素时，（类似插入过程）
    - 通过散列函数求出要查找元素的键值对应的散列值，
    - 然后比较数组中下标为散列值的元素和要查找的元素
    - 如果相等，则说明就是我们要找的元素；
    - 否则就顺序往后依次查找
    - 如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中
  - 在散列表中删除元素时，（不能单纯地把要删除的元素设置为空）
    - 在查找的时候，一旦通过线性探测方法，找到一个空闲位置，
    - 就可以认定散列表中不存在这个数据
    - 但是，如果这个空闲位置是我们后来删除的，
    - 就会导致原来的查找算法失效
    - 本来存在的数据，会被认定为不存在
  - 如何解决删除操作的问题呢？
    - 可以将删除的元素，特殊标记为 deleted
    - 当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测
  - 线性探测法其实存在很大问题
    - 当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久
    - 极端情况下，可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)
    - 同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据
- 二次探测（Quadratic probing）
  - 线性探测每次探测的步长是 1，
  - 下标序列：`hash(key)+0，hash(key)+1，hash(key)+2……`
  - 二次探测探测的步长是原来的“二次方”，
  - 下标序列就:`hash(key)+0，hash(key)+1 ，hash(key)+2 ……`
- 双重散列（Double hashing）
  - 使用一组散列函数`hash1(key)，hash2(key)，hash3(key)……`
  - 先用第一个散列函数，如果计算得到的存储位置已经被占用，
  - 再用第二个散列函数，
  - 依次类推，直到找到空闲的存储位置

优点

- 散列表中的数据都存储在数组中，可以有效地利用 CPU缓存加快查询速度
- **序列化**简单,链表法包含指针不容易序列化

缺点

- 删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据
- 所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高
  - 装载因子的上限不能太大
  - 导致这种方法比链表法更浪费内存空间

适合场景

- 当**数据量比较小、装载因子小**的时候，适合采用开放寻址法
- Java 中的ThreadLocalMap

######链表法

相比开放寻址法，要简单很多

核心思想:

- 在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，
- 所有散列值相同的元素都放到相同槽位对应的链表中

插入

- 通过散列函数计算出对应的散列槽位，
- 将其插入到对应链表中即可，
- 插入的时间复杂度是 O(1)

查找、删除

- 通过散列函数计算出对应的槽，
- 然后遍历链表查找或者删除
- 时间复杂度跟链表的长度 k 成正比，也就是 O(k)
  - 理论上讲，k=n/m，
  - 其中 n 表示散列中数据的个数，
  - m 表示散列表中“槽”的个数

优点：

- 链表法对内存的利用率比开放寻址法要高
- 链表法比开放寻址法，对大装载因子的容忍度更高

缺点：

- 链表要存储指针，所以对于比较小的对象的存储，是比较消耗内存的
- 链表中的结点是零散分布在内存中的，不是连续的，对 CPU 缓存是不友好

可以实现一个更加高效的散列表

- 将链表法中的链表改造为其他高效的动态数据结构
  - 跳表
  - 红黑树
- 即便出现散列冲突，极端情况下
  - 所有的数据都散列到同一个桶内，
  - 最终退化成的散列表的查找时间也只不过是 `O(logn)`
  - 有效避免了散列碰撞攻击

适合场景：

- 基于链表的散列冲突处理方法比较适合存储**大对象、大数据量**的散列表，
- 比起开放寻址法，
  - 更加灵活，
  - 支持更多的优化策略，比如用红黑树代替链表

##### 装载因子

不管采用哪种探测方法，

- 当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高

- 为了尽可能保证散列表的操作效率尽可能保证散列表中有一定比例的空闲槽位

用装载因子（load factor）来表示空位的多少

- 装载因子的计算公式:

`散列表的装载因子 = 填入表中的元素个数 / 散列表的长度`



##### 举个栗子

Word 文档中单词拼写检查功能是如何实现的？

- 常用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，

- 这个大小完全可以放在内存里面。所以可以用散列表来存储整个英文单词词典

- 当用户输入某个英文单词时，拿用户输入的单词去散列表中查找如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示



#### 散列表的性能

散列表的查询效率并不能笼统地说成是 O(1)，跟

- 散列函数、
- 装载因子、
- 散列冲突等都有关系

在极端情况下，

- 有些恶意的攻击者，通过精心构造的数据，
- 使得所有的数据经过散列函数之后，都散列到同一个槽里
- 如果使用的是基于链表的冲突解决方法，
- 那这个时候，散列表就会**退化为链表**，
- 查询的时间复杂度就从 O(1) 急剧**退化为 O(n)**

这样就有可能

- 因为查询操作消耗大量 CPU或者线程资源，
- 导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的
- 这就是**散列表碰撞攻击的基本原理**



#### 动态扩容

#####装载因子过大

装载因子越大，

- 说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大
- 不仅插入数据的过程要多次寻址或者拉很长的链，
- 查找的过程也会变得很慢

对于静态散列来说

- 数据已知
- 很容易根据数据的特点、分布设计出完美的、极少冲突的散列函数

对于动态散列来说

- 数据集合是频繁变动的
- 无法预估将要加入的数据个数
- 随着数据慢慢加入，装载因子就会慢慢变大
- 如何处理？（动态扩容：类似数组，栈，队列）
  - 假设每次扩容都申请一个原来散列表大小两倍的空间
  - 装载因子就下降为原来的一半
  - 散列表的大小变了，数据的存储位置也变了，需要通过散列函数重新计算每个数据的存储位置
- 动态扩容的散列表，插入操作的时间复杂度
  - 最好情况下，不需要扩容，最好时间复杂度是 `O(1)`
  - 最坏情况下，散列表装载因子过高，启动扩容，
    - 需要重新申请内存空间，重新计算哈希位置，
    - 并且搬移数据，
    - 所以时间复杂度是` O(n)`
  - 用摊还分析法，均摊情况下，时间复杂度接近最好情况，是 `O(1)`



##### 避免低效地扩容

大部分情况下，

- 动态扩容的散列表插入一个数据都很快，

但是在特殊情况下，

- 当装载因子已经到达阈值，需要先进行扩容，再插入数据

- 这时插入数据就会变得很慢，
- 甚至会无法接受

为了解决一次性扩容耗时过多的情况，

- 可以将扩容操作穿插在插入操作的过程中，分批完成
- 当装载因子触达阈值之后，
  - 只申请新空间，但并不将老的数据搬移到新散列表中
- 当有新数据要插入时，
  - 将新数据插入新散列表中，
  - 并且从老的散列表中拿出一个数据放入到新散列表
  - 插入一个数据到散列表，重复上面的过程
- 经过多次插入操作之后，
  - 老的散列表中的数据就一点一点全部搬移到新散列表中了
  - 没有了集中的一次性数据搬移，插入操作就都变得很快了

对于查询操作，

- 为了兼容了新、老散列表中的数据，
- 先从新散列表中查找，
- 如果没有找到，再去老的散列表中查找

通过这样均摊的方法，

- 将一次性扩容的代价，均摊到多次插入操作中，
- **避免了一次性扩容耗时过多的情况**
- 这种实现方式，**任何情况下，插入一个数据的时间复杂度都是 O(1)**



#### 举个栗子

Java中的 HashMap 这样一个工业级的散列表

1. 初始大小

   - HashMap 默认的初始大小是 16
   - 事先知道大概的数据量有多大，
     - 可以通过修改默认初始大小，减少动态扩容的次数，
     - 这样会大大提高 HashMap 的性能

2. 装载因子和动态扩容

   - 最大装载因子默认是 0.75
   - 当 HashMap 中元素个数超过 0.75*capacity时
     - 扩容为原来的两倍

3. 散列冲突解决方法

   - HashMap 底层采用链表法来解决冲突
   - 当链表长度太长（默认超过 8）时，链表就转换为红黑树
   - 当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表

4. 散列函数

   ```java
   int hash(Object key) {
       int h = key.hashCode()；
       return (h ^ (h >>> 16)) & (capitity -1); 
       //capicity 表示散列表的大小
   }
   ```

   hashCode() 返回的是 Java 对象的 hash code

   ```java
   public int hashCode() {
       int var1 = this.hash;
       if(var1 == 0 && this.value.length > 0) {
       	char[] var2 = this.value;
           for(int var3 = 0; var3 < this.value.length; ++var3) {
               var1 = 31 * var1 + var2[var3];
           }
       	this.hash = var1;
       }
       return var1;
   }
   ```

#### 如何设计的一个工业级的散列函数？

何为一个工业级的散列表？

- 支持快速的查询、插入、删除操作；
- 内存占用合理，不能浪费过多的内存空间；
- 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况

如何实现?

- 设计一个合适的散列函数；
- 定义装载因子阈值，并且设计动态扩容策略；
- 选择合适的散列冲突解决方法



#### 为什么散列表和链表经常会一起使用？

三个栗子：

##### LRU 缓存淘汰算法

一个缓存（cache）系统主要包含下面几个操作：

- 往缓存中添加一个数据；
- 从缓存中删除一个数据；
- 在缓存中查找一个数据

三个操作都要涉及“查找”操作,单纯地采用链表的话，时间复杂度只能是 `O(n)`,

散列表和链表两种数据结构组合使用，可以将三个操作的时间复杂度都降低到 `O(1)`

通过链表实现 LRU 缓存淘汰算法

- 需要维护一个按照访问时间从大到小有序排列的链表结构
- 缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，直接将链表头部的结点删除
- 当要缓存某个数据的时候，
  - 先在链表中查找这个数据
  - 如果没有找到，则直接将数据放到链表的尾部；
  - 如果找到了，就把它移动到链表的尾部
- 查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间是 `O(n)`

散列表和链表两种数据结构组合使用

- 使用双向链表存储数据，
  - 存储数据（data）
  - 前驱指针（prev）
  - 后继指针（next）
  - 特殊指针（hnext）
- hnext 有什么作用
  - 前驱和后继指针是为了将结点串在双向链表中
  - hnext 指针是为了将结点串在散列表的拉链中
- 时间复杂度：O(1)
  - 查找一个数据
    - 散列表中查找数据的时间复杂度接近 O(1)，
    - 当找到数据之后，将它移动到双向链表的尾部
  - 删除一个数据
    - 需要找到数据所在的结点，然后将结点删除
    - 借助散列表，可以在 O(1) 时间复杂度里找到要删除的结点
    - 双向链表可以通过前驱指针 O(1) 时间复杂度获取前驱结点
    - 所以在双向链表中，删除结点只需要 O(1) 的时间复杂度
  - 添加一个数据
    - 需要先看这个数据是否已经在缓存中
      - 如果已经在其中，
        - 需要将其移动到双向链表的尾部；
      - 如果不在其中，
        - 还要看缓存有没有满
          - 如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部；
          - 如果没有满，就直接将数据放到链表的尾部
    - 整个过程涉及的查找操作都可以通过散列表来完成
    - 比如删除头结点、链表尾部插入数据等，都可以在 O(1) 的时间复杂度内完成
    - 因此，添加一个数据的时间复杂度是O(1)

##### Redis 有序集合

按照键值构建一个散列表，同时，借助跳表结构

##### LinkedHashMap

通过双向链表和散列表这两种数据结构组合实现



#####为什么散列表和链表经常一块使用？

散列表虽然支持高效的数据插入、删除、查找操作，

但是散列表中的数据都是通过散列函数打乱之后无规律存储的

- 无法支持按照某种顺序快速地遍历数据
- 散列表是动态数据结构
- 将散列表和链表（或者跳表）结合在一起使用